{"cells":[{"cell_type":"markdown","source":["## Add some Spark in the data\n\nHere, we put a pandas DataFrame into a Spark cluster! The SparkSession class has a method for this.\n\nThe .createDataFrame() method takes a pandas DataFrame and returns a Spark DataFrame.\n\nThe output of this method is stored locally, not in the SparkSession catalog. This means that all the Spark DataFrame methods can be used on it, but data in other contexts is not accessible.\n\nFor example, a SQL query (using the .sql() method) that references the DataFrame will throw an error. To access the data in this way, it has to be saved as a temporary table. This is done using the .createTempView() Spark DataFrame method, which takes as its only argument the name of the temporary table that needs to be registered. This method registers the DataFrame as a table in the catalog, but as this table is temporary, and it can only be accessed from the specific SparkSession used to create the Spark DataFrame.\n\nThere is also the method .createOrReplaceTempView(). This safely creates a new temporary table if nothing was there before, or updates an existing table if one was already defined. This method to is used to avoid running into problems with duplicate tables."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"997c964b-cfe7-4eb3-8a69-ff5c0a531215"}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\n# Create pd_temp\npd_temp = pd.DataFrame(np.random.random(10))\n\n# Create spark_temp from pd_temp\nspark_temp = spark.createDataFrame(pd_temp)\n\n# Examine the tables in the catalog\nprint(spark.catalog.listTables())\n\n# Add spark_temp to the catalog\nspark_temp.createOrReplaceTempView(\"temp\")\n\n# Examine the tables in the catalog again\nprint(spark.catalog.listTables())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd77fe6d-34d9-4d74-ac5b-5cd35a355102"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"spark_temp","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"0","nullable":true,"type":"double"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">[Table(name=&#39;flights&#39;, database=&#39;default&#39;, description=None, tableType=&#39;MANAGED&#39;, isTemporary=False)]\n[Table(name=&#39;flights&#39;, database=&#39;default&#39;, description=None, tableType=&#39;MANAGED&#39;, isTemporary=False), Table(name=&#39;temp&#39;, database=None, description=None, tableType=&#39;TEMPORARY&#39;, isTemporary=True)]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[Table(name=&#39;flights&#39;, database=&#39;default&#39;, description=None, tableType=&#39;MANAGED&#39;, isTemporary=False)]\n[Table(name=&#39;flights&#39;, database=&#39;default&#39;, description=None, tableType=&#39;MANAGED&#39;, isTemporary=False), Table(name=&#39;temp&#39;, database=None, description=None, tableType=&#39;TEMPORARY&#39;, isTemporary=True)]\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"05. Pandas to Spark Dataframes","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1227023265356611}},"nbformat":4,"nbformat_minor":0}
